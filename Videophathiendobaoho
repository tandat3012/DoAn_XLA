# ===================== IMPORT =====================
import cv2
import numpy as np
import gradio as gr
import os
import tempfile
from datetime import datetime

# ===================== CONFIG =====================
MODEL_PATH = r"D:\opencv\helmet_yolov5_tiny.onnx"   # sá»­a náº¿u cáº§n
LABELS = ["Person", "Helmet", "No-Helmet"]
CONF_THRES = 0.4
NMS_THRES = 0.45
INPUT_SIZE = 640

os.makedirs("logs", exist_ok=True)

# ===================== LOAD MODEL =====================
net = None
if os.path.exists(MODEL_PATH):
    try:
        net = cv2.dnn.readNet(MODEL_PATH)
        print("Loaded model:", MODEL_PATH)
    except Exception as e:
        print("Cannot load model:", e)
        net = None
else:
    print("Model file not found:", MODEL_PATH)

# ===================== YOLO DETECTION =====================
def yolo_detect(frame):
    if net is None:
        return frame, 0

    h, w = frame.shape[:2]

    blob = cv2.dnn.blobFromImage(
        frame, 1/255.0, (INPUT_SIZE, INPUT_SIZE),
        swapRB=True, crop=False
    )
    net.setInput(blob)
    outputs = net.forward()

    boxes, scores, class_ids = [], [], []

    for det in outputs[0]:
        conf = det[4]
        if conf < CONF_THRES:
            continue

        class_scores = det[5:]
        class_id = np.argmax(class_scores)
        score = class_scores[class_id] * conf

        if score < CONF_THRES:
            continue

        cx, cy, bw, bh = det[0:4]
        x = int((cx - bw / 2) * w)
        y = int((cy - bh / 2) * h)
        bw = int(bw * w)
        bh = int(bh * h)

        boxes.append([x, y, bw, bh])
        scores.append(float(score))
        class_ids.append(class_id)

    indices = cv2.dnn.NMSBoxes(boxes, scores, CONF_THRES, NMS_THRES)

    no_helmet_count = 0

    if len(indices) > 0:
        for i in indices.flatten():
            x, y, bw, bh = boxes[i]
            cls = class_ids[i]
            label = LABELS[cls]
            color = (0, 255, 0)

            if label == "No-Helmet":
                color = (0, 0, 255)
                no_helmet_count += 1

            cv2.rectangle(frame, (x, y), (x + bw, y + bh), color, 2)
            cv2.putText(
                frame, f"{label} {scores[i]:.2f}",
                (x, y - 5),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                color,
                2
            )

    return frame, no_helmet_count

# ===================== LOG VI PHáº M =====================
def write_log(count):
    if count <= 0:
        return
    with open("logs/violation_log.txt", "a", encoding="utf-8") as f:
        f.write(f"{datetime.now()} - No Helmet: {count}\n")

# ===================== IMAGE =====================
def detect_image(img):
    if img is None:
        return None

    frame = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
    frame, count = yolo_detect(frame)
    write_log(count)

    return cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

# ===================== VIDEO =====================
def detect_video(video_path):
    if net is None:
        return None

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        return None

    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)

    out_path = tempfile.mktemp(suffix=".mp4")
    out = cv2.VideoWriter(
        out_path,
        cv2.VideoWriter_fourcc(*"mp4v"),
        fps,
        (w, h)
    )

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        frame, count = yolo_detect(frame)
        write_log(count)
        out.write(frame)

    cap.release()
    out.release()

    return out_path

# ===================== SAFE WRAPPER =====================
def detect_video_safe(video_file):
    if net is None:
        print("Model not loaded â€“ skip video")
        return None

    if video_file is None:
        return None

    path = video_file["name"] if isinstance(video_file, dict) else video_file
    if not path or not os.path.exists(path):
        return None

    return detect_video(path)

# ===================== GRADIO UI =====================
with gr.Blocks(title="YOLO PPE Detection") as demo:
    gr.Markdown("## ðŸ¦º YOLOv5 PPE Detection (Helmet / No-Helmet)")

    with gr.Tab("ðŸ“· áº¢nh"):
        img_in = gr.Image(type="numpy")
        img_out = gr.Image()
        btn_img = gr.Button("Detect Image")
        btn_img.click(detect_image, img_in, img_out)

    with gr.Tab("ðŸŽžï¸ Video"):
        video_in = gr.Video()
        video_out = gr.Video(autoplay=True)
        btn_vid = gr.Button("Detect Video")
        btn_vid.click(detect_video_safe, video_in, video_out)

    gr.Markdown(
        "ðŸ“Œ **LÆ°u Ã½:** Náº¿u model chÆ°a load, video sáº½ khÃ´ng xá»­ lÃ½ Ä‘á»ƒ trÃ¡nh crash."
    )

demo.launch()

Äoáº¡n code cháº¡y Ä‘Æ°á»£c k cháº¡y ra video Ä‘á»ƒ nháº­n diá»‡n Ä‘Æ°á»£c
